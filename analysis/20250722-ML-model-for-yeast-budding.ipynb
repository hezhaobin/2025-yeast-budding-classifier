{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14691bba-dfc8-4fa4-92b8-883e0b80d106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d93502-23c2-46f8-892f-ab8b7597438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def load_and_explore_data(csv_file):\n",
    "    \"\"\"Load CSV and perform initial exploration\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"DATA LOADING AND EXPLORATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nBasic statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Check target variable distribution\n",
    "    target_col = 'budded'  # Adjust this to match your CSV column name\n",
    "    if target_col in df.columns:\n",
    "        print(f\"\\nTarget variable distribution:\")\n",
    "        print(df[target_col].value_counts())\n",
    "        print(f\"Class balance: {df[target_col].value_counts(normalize=True)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def visualize_data(df, target_col='budded'):\n",
    "    \"\"\"Create visualizations to understand the data\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"DATA VISUALIZATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Identify feature columns (assuming they're numeric and not the target)\n",
    "    feature_cols = [col for col in df.columns if col != target_col and df[col].dtype in ['int64', 'float64']]\n",
    "    \n",
    "    # Create subplots for distributions\n",
    "    n_features = len(feature_cols)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, feature in enumerate(feature_cols[:4]):  # Show first 4 features\n",
    "        if i < len(axes):\n",
    "            # Box plots by class\n",
    "            df.boxplot(column=feature, by=target_col, ax=axes[i])\n",
    "            axes[i].set_title(f'{feature} by {target_col}')\n",
    "            axes[i].set_xlabel(target_col)\n",
    "            axes[i].set_ylabel(feature)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation_matrix = df[feature_cols].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_cols\n",
    "\n",
    "def prepare_data(df, feature_cols, target_col='budded'):\n",
    "    \"\"\"Prepare features and target for modeling\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"DATA PREPARATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    X = df[feature_cols]\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Convert target to binary if it's string\n",
    "    if y.dtype == 'object':\n",
    "        y = y.map({'budded': 1, 'unbudded': 0})  # Adjust mapping as needed\n",
    "        print(\"Target variable mapped: budded=1, unbudded=0\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape}\")\n",
    "    print(f\"Test set size: {X_test.shape}\")\n",
    "    print(f\"Feature columns: {feature_cols}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_decision_tree(X_train, X_test, y_train, y_test, feature_names):\n",
    "    \"\"\"Train and evaluate decision tree\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"DECISION TREE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Train decision tree with cross-validation for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 7, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt_grid = GridSearchCV(dt, param_grid, cv=5, scoring='roc_auc')\n",
    "    dt_grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best parameters: {dt_grid.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {dt_grid.best_score_:.3f}\")\n",
    "    \n",
    "    # Get best model\n",
    "    best_dt = dt_grid.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = best_dt.predict(X_test)\n",
    "    y_prob = best_dt.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"\\nTest set performance:\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': best_dt.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Visualize decision tree (simplified)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(best_dt, max_depth=3, feature_names=feature_names, \n",
    "              class_names=['unbudded', 'budded'], filled=True, rounded=True)\n",
    "    plt.title('Decision Tree (max_depth=3 for visualization)')\n",
    "    plt.show()\n",
    "    \n",
    "    # Extract thresholds from the tree\n",
    "    print(f\"\\nDecision Tree Thresholds:\")\n",
    "    tree = best_dt.tree_\n",
    "    feature_names_array = np.array(feature_names)\n",
    "    \n",
    "    def get_tree_thresholds(tree, feature_names):\n",
    "        thresholds = {}\n",
    "        for i in range(tree.node_count):\n",
    "            if tree.children_left[i] != tree.children_right[i]:  # Not a leaf\n",
    "                feature_idx = tree.feature[i]\n",
    "                feature_name = feature_names[feature_idx]\n",
    "                threshold = tree.threshold[i]\n",
    "                if feature_name not in thresholds:\n",
    "                    thresholds[feature_name] = []\n",
    "                thresholds[feature_name].append(threshold)\n",
    "        \n",
    "        # Sort thresholds for each feature\n",
    "        for feature in thresholds:\n",
    "            thresholds[feature] = sorted(list(set(thresholds[feature])))\n",
    "        \n",
    "        return thresholds\n",
    "    \n",
    "    thresholds = get_tree_thresholds(tree, feature_names_array)\n",
    "    for feature, thresh_list in thresholds.items():\n",
    "        print(f\"{feature}: {thresh_list}\")\n",
    "    \n",
    "    return best_dt, feature_importance\n",
    "\n",
    "def train_random_forest(X_train, X_test, y_train, y_test, feature_names):\n",
    "    \"\"\"Train and evaluate random forest\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"RANDOM FOREST ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Train random forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    print(f\"Cross-validation ROC AUC: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"Test set ROC AUC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Feature importance\n",
    "    rf_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nRandom Forest Feature Importance:\")\n",
    "    print(rf_importance)\n",
    "    \n",
    "    return rf, rf_importance\n",
    "\n",
    "def compare_models(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Compare multiple models\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"MODEL COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    models = {\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42),\n",
    "        'SVM': SVC(probability=True, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Scale features for SVM and Logistic Regression\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if name in ['SVM', 'Logistic Regression']:\n",
    "            X_tr, X_te = X_train_scaled, X_test_scaled\n",
    "        else:\n",
    "            X_tr, X_te = X_train, X_test\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_tr, y_train)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_tr, y_train, cv=5, scoring='roc_auc')\n",
    "        \n",
    "        # Test prediction\n",
    "        y_prob = model.predict_proba(X_te)[:, 1]\n",
    "        test_auc = roc_auc_score(y_test, y_prob)\n",
    "        \n",
    "        results[name] = {\n",
    "            'CV_AUC_mean': cv_scores.mean(),\n",
    "            'CV_AUC_std': cv_scores.std(),\n",
    "            'Test_AUC': test_auc\n",
    "        }\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  CV ROC AUC: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "        print(f\"  Test ROC AUC: {test_auc:.3f}\")\n",
    "        print()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_feature_importance_comparison(dt_importance, rf_importance):\n",
    "    \"\"\"Plot feature importance comparison\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"FEATURE IMPORTANCE COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Merge importance scores\n",
    "    comparison = dt_importance.merge(rf_importance, on='feature', suffixes=('_dt', '_rf'))\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(comparison))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, comparison['importance_dt'], width, label='Decision Tree', alpha=0.8)\n",
    "    plt.bar(x + width/2, comparison['importance_rf'], width, label='Random Forest', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title('Feature Importance: Decision Tree vs Random Forest')\n",
    "    plt.xticks(x, comparison['feature'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Feature importance ranking:\")\n",
    "    print(comparison[['feature', 'importance_dt', 'importance_rf']])\n",
    "\n",
    "# Main execution function\n",
    "def main(csv_file):\n",
    "    \"\"\"Main analysis pipeline\"\"\"\n",
    "    try:\n",
    "        # Step 1: Load and explore data\n",
    "        df = load_and_explore_data(csv_file)\n",
    "        \n",
    "        # Step 2: Visualize data\n",
    "        feature_cols = visualize_data(df)\n",
    "        \n",
    "        # Step 3: Prepare data\n",
    "        X_train, X_test, y_train, y_test = prepare_data(df, feature_cols)\n",
    "        \n",
    "        # Step 4: Train decision tree\n",
    "        best_dt, dt_importance = train_decision_tree(X_train, X_test, y_train, y_test, feature_cols)\n",
    "        \n",
    "        # Step 5: Train random forest\n",
    "        best_rf, rf_importance = train_random_forest(X_train, X_test, y_train, y_test, feature_cols)\n",
    "        \n",
    "        # Step 6: Compare all models\n",
    "        model_results = compare_models(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # Step 7: Compare feature importance\n",
    "        plot_feature_importance_comparison(dt_importance, rf_importance)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ANALYSIS COMPLETE!\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Key takeaways:\")\n",
    "        print(\"1. Check the feature importance rankings to see which morphological parameters matter most\")\n",
    "        print(\"2. Decision tree thresholds show exact cutoff values for classification\")\n",
    "        print(\"3. Model comparison helps choose the best approach for your data\")\n",
    "        print(\"4. Visualizations reveal relationships between features and budding state\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure your CSV file has the correct column names and format\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'your_data.csv' with your actual file path\n",
    "    csv_file = 'your_data.csv'\n",
    "    \n",
    "    # Note: Make sure your CSV has columns like:\n",
    "    # - 'budded' (or similar) for the target variable (budded/unbudded)\n",
    "    # - 'circularity', 'perimeter', 'area', 'aspect_ratio' for features\n",
    "    # Adjust column names in the script as needed\n",
    "    \n",
    "    main(csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
